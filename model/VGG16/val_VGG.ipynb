{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aeb39ef-a338-4c5e-99c7-435a0aac31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b7d546-cbac-4cf2-a8f4-87d8e9c8dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model_path, val_path):\n",
    "    # Hardware configuration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Validation data configuration\n",
    "    val_dir = val_path\n",
    "    if not os.path.exists(val_dir):\n",
    "        raise FileNotFoundError(f\"Validation directory not found: {val_dir}\")\n",
    "\n",
    "    # Validation transforms\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create dataset and loader\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Model initialization\n",
    "    model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze feature parameters\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Modify classifier\n",
    "    num_classes = len(val_dataset.classes)\n",
    "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "    \n",
    "    # Load trained weights\n",
    "    model_path = model_path\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize metrics\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Get class probabilities\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_acc = running_corrects.double() / len(val_dataset)\n",
    "    sk_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    val_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    val_roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Print comprehensive results\n",
    "    print(f\"\\nValidation Metrics:\")\n",
    "    print(f\"Manual Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Sklearn Accuracy: {sk_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall: {val_recall:.4f}\")\n",
    "    print(f\"F1-Score: {val_f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {val_roc_auc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30c073f-3c16-4cb8-b81e-79de766b67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Validation Metrics:\n",
      "Manual Accuracy: 0.9032\n",
      "Sklearn Accuracy: 0.9032\n",
      "Precision: 0.8816\n",
      "Recall: 0.7635\n",
      "F1-Score: 0.7838\n",
      "ROC-AUC: 0.9742\n",
      "\n",
      "Confusion Matrix:\n",
      "[[113   3   3   0   0]\n",
      " [  4  14   2   0   0]\n",
      " [  0   2  86   0   3]\n",
      " [  0   0   1   3   6]\n",
      " [  0   0   3   0  36]]\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/best_model.pth', '../EBH-HE-IDS/ColHis-IDS_split/test/200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38490e4d-322c-4888-966c-34a960d2fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Validation Metrics:\n",
      "Manual Accuracy: 0.8136\n",
      "Sklearn Accuracy: 0.8136\n",
      "Precision: 0.6513\n",
      "Recall: 0.6257\n",
      "F1-Score: 0.6308\n",
      "ROC-AUC: 0.9453\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   8   6   0   0]\n",
      " [  6   7   7   0   0]\n",
      " [  0   4  82   0   5]\n",
      " [  0   0   2   2   6]\n",
      " [  0   0   5   3  31]]\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/vgg16_model_magnification200.pth', '../EBH-HE-IDS/ColHis-IDS_split/test/200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9abc5b07-c4dd-4196-9194-40bd330310f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "validate_model() missing 1 required positional argument: 'val_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# alexnet\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m     validate_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/9444/alexnet_EBHI_mag_200.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: validate_model() missing 1 required positional argument: 'val_path'"
     ]
    }
   ],
   "source": [
    "# alexnet\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/alexnet_EBHI_mag_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a37f99-b4cb-479f-8bfd-e757e8ac21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/densenet161_EBHI_mag_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c24249-ec28-4737-a498-547842b811e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# googlenet\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/googlenet_EBHI_mag_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60431f1-6d5f-4562-9d27-38ad8a37c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/resnet50_EBHI_mag_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755a2a7-2ddc-4b6c-92a7-0b15524f878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/mobilenet_EBHI_mag_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be509053-cb19-4421-b240-133e4b2b2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improved\n",
    "if __name__ == \"__main__\":\n",
    "    validate_model('../model/9444/improved_EBHI_mag_200.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
